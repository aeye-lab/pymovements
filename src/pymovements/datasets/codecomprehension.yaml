name: CodeComprehension

info: |
    CodeComprehension dataset :cite:p:`CodeComprehension`.

    This dataset includes eye-tracking-while-code-reading data from participants in a single
    session. Eye movements are recorded at a sampling frequency of 1,000 Hz using an
    EyeLink 1000 eye tracker and are provided as pixel coordinates.

    The participant is instructed to read the code snippet and answer a code comprehension question.

    If you use the dataset, please cite:

    @article{CodeComprehension,
      author = {Alakmeh, Tarek and Reich, David and J\"{a}ger, Lena and Fritz, Thomas},
      title = {Predicting Code Comprehension: A Novel Approach to
      Align Human Gaze with Code using Deep Neural Networks},
      year = {2024},
      issue_date = {July 2024},
      publisher = {Association for Computing Machinery},
      address = {New York, NY, USA},
      volume = {1},
      number = {FSE},
      url = {https://doi.org/10.1145/3660795},
      doi = {10.1145/3660795},
      journal = {Proc. ACM Softw. Eng.},
      month = {jul},
      articleno = {88},
      numpages = {23},
    }

has_files:
  gaze: false
  precomputed_events: true
  precomputed_reading_measures: false

mirrors:
  precomputed_events:
    - https://zenodo.org/

resources:
  precomputed_events:
    - resource: "records/11123101/files/Predicting%20Code%20Comprehension%20Package.zip?download=1"
      filename: "data.zip"
      md5: "3a3c6fb96550bc2c2ddcf5d458fb12a2"

extract:
  precomputed_events: true

filename_format:
  precomputed_events: 'fix_report_P{subject_id:s}.txt'

filename_format_schema_overrides:
  precomputed_events:
    subject_id: !polars.Utf8

custom_read_kwargs:
  precomputed_events:
    separator: "\t"
    null_values: "."
    quote_char: '"'
