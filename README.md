<p style="text-align:center;">
<img width="110%" height="110%" alt="pymovements"
 src="https://raw.githubusercontent.com/aeye-lab/pymovements/main/docs/source/_static/logo.svg"
 onerror="this.onerror=null;this.src='./docs/source/_static/logo.svg';"/>
</p>

---

[![PyPI Latest Release](https://img.shields.io/pypi/v/pymovements.svg)](https://pypi.python.org/pypi/pymovements/)
[![Conda Latest Release](https://img.shields.io/conda/vn/conda-forge/pymovements)](https://anaconda.org/conda-forge/pymovements)
[![PyPI status](https://img.shields.io/pypi/status/pymovements.svg)](https://pypi.python.org/pypi/pymovements/)
[![Python version](https://img.shields.io/pypi/pyversions/pymovements.svg)](https://pypi.python.org/pypi/pymovements/)
![Operating System](https://img.shields.io/badge/os-linux%20%7C%20macOS%20%7C%20windows-blue)
[![License](https://img.shields.io/pypi/l/pymovements.svg)](https://github.com/aeye-lab/pymovements/blob/master/LICENSE.txt)
[![Test Status](https://img.shields.io/github/actions/workflow/status/aeye-lab/pymovements/tests.yml?label=tests)](https://github.com/aeye-lab/pymovements/actions/workflows/tests.yml)
[![Documentation Status](https://readthedocs.org/projects/pymovements/badge/?version=latest)](https://pymovements.readthedocs.io/en/latest/?badge=latest)
[![codecov](https://codecov.io/github/aeye-lab/pymovements/branch/main/graph/badge.svg?token=QY3NDHAT2C)](https://app.codecov.io/gh/aeye-lab/pymovements)
[![PyPI downloads/month](https://img.shields.io/pypi/dm/pymovements.svg)](https://pypistats.org/packages/pymovements)
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/aeye-lab/pymovements/HEAD?labpath=docs%2Fsource%2Ftutorials)


pymovements is an open-source python package for processing eye movement data. It provides a simple
interface to download publicly available datasets, preprocess gaze data, detect oculomotoric events
and render plots to visually analyze your results.

- **Website:** https://github.com/aeye-lab/pymovements
- **Documentation:** https://pymovements.readthedocs.io
- **Source code:** https://github.com/aeye-lab/pymovements
- **Mailing list:** pymovements-list@uni-potsdam.de
- **Contributing:** https://github.com/aeye-lab/pymovements/blob/main/CONTRIBUTING.md
- **Bug reports:** https://github.com/aeye-lab/pymovements/issues
- **PyPI package:** https://pypi.org/project/pymovements
- **Conda package:** https://anaconda.org/conda-forge/pymovements


## Getting Started

Check out our guide on how to install *pymovements* and get started here:
[Installation](https://pymovements.readthedocs.io/en/stable/getting-started.html)

We provide a range of tutorial aimed at beginners:
[Tutorials](https://pymovements.readthedocs.io/en/stable/tutorials/index.html)

The complete reference of the package can be found here:
[API Reference](https://pymovements.readthedocs.io/en/stable/reference/index.html)


## Contributing

We welcome any sort of contribution to pymovements!

For a detailed guide, please refer to our [CONTRIBUTING.md](CONTRIBUTING.md) first.

If you have any questions, please [open an issue](
https://github.com/aeye-lab/pymovements/issues/new/choose) or write us at
[pymovements-list@uni-potsdam.de](mailto:pymovements-list@uni-potsdam.de)


## Citing

If you are using pymovements in your research, we would be happy if you cite our work by using the following BibTex entry:

```bibtex
@inproceedings{pymovements,
    author = {Krakowczyk, Daniel G. and Reich, David R. and Chwastek, Jakob and Jakobi, Deborah N.
   and Prasse, Paul and Süss, Assunta and Turuta, Oleksii and Kasprowski, Paweł
   and Jäger, Lena A.},
    title = {pymovements: A Python Package for Processing Eye Movement Data},
    year = {2023},
    isbn = {979-8-4007-0150-4/23/05},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3588015.3590134},
    doi = {10.1145/3588015.3590134},
    booktitle = {2023 Symposium on Eye Tracking Research and Applications},
    location = {Tubingen, Germany},
    series = {ETRA '23},
}
```

There is also a preprint available on [arxiv](https://arxiv.org/abs/2304.09859).
